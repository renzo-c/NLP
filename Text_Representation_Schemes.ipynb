{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Vectorization Approaches"
      ],
      "metadata": {
        "id": "y2wIcLp8yLNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Representation Schemes"
      ],
      "metadata": {
        "id": "XMeK4ImG4BvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding"
      ],
      "metadata": {
        "id": "6O07ryEF4IOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbLwJC9Xw1iM",
        "outputId": "8cd0fe40-fa70-4736-e29e-1e4cfc3ce989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'It': 1, 'is': 9, 'a': 3, 'long': 4, 'stablished': 5, 'fact': 6, 'that': 7, 'Lorem': 8, 'Ipsum': 9, 'simply': 10}\n",
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "count = 0\n",
        "vocab = {}\n",
        "processed_docs = [\n",
        "    \"It is a long stablished fact that is\", \n",
        "    \"Lorem Ipsum is simply\"\n",
        "    ]\n",
        "\n",
        "for doc in processed_docs:\n",
        "  for word in doc.split():\n",
        "    if word not in vocab:\n",
        "      count += 1\n",
        "    vocab[word] = count\n",
        "\n",
        "print(vocab) \n",
        "print(len(vocab))\n",
        "\n",
        "def get_onehot_vector(somestring):\n",
        "  onehot_encoded = []\n",
        "  for word in somestring.split():\n",
        "    temp = [0]*len(vocab)\n",
        "    if word in vocab:\n",
        "      temp[vocab[word]-1]=1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
        "    onehot_encoded.append(temp)\n",
        "  return onehot_encoded\n",
        "\n",
        "get_onehot_vector(processed_docs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of Words"
      ],
      "metadata": {
        "id": "NCU7PD4e4OnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "# Build a BOW representation for the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "# Look at the vocabulary mapping\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary)\n",
        "\n",
        "# See the BOW representation for first 2 documents\n",
        "print(\"BoW representation for 'It is a long stablished fact that is': \", bow_rep[0].toarray())\n",
        "print(\"BoW representation for 'Loren Ipsum is simply': \", bow_rep[1].toarray())\n",
        "\n",
        "# Get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"long stablished Loren is is long\"])\n",
        "print(\"long stablished Loren is\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgcShvvmk24s",
        "outputId": "5bf1c165-8f76-417c-d489-7e12434afddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our vocabulary:  None\n",
            "BoW representation for 'It is a long stablished fact that is':  [[1 0 2 1 1 0 0 1 1]]\n",
            "BoW representation for 'Loren Ipsum is simply':  [[0 1 1 0 0 1 1 0 0]]\n",
            "long stablished Loren is [[0 0 2 0 2 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of N-grams"
      ],
      "metadata": {
        "id": "QvwWGnELxpJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# quick pre-process step\n",
        "print(processed_docs)\n",
        "processed_docs2 = [doc.lower().replace(\".\", \"\") for doc in processed_docs]\n",
        "\n",
        "print(processed_docs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21cb243-ab26-4d47-c623-49a9d3e4efd7",
        "id": "gBsQBxTjxvgN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It is a long stablished fact that is', 'Lorem Ipsum is simply']\n",
            "['it is a long stablished fact that is', 'lorem ipsum is simply']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance with uni, bi, and trigrams\n",
        "count_vect = CountVectorizer(ngram_range=(1, 3))\n",
        "\n",
        "# build a bow representation of the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs2)\n",
        "\n",
        "# Look at the vocabulary mapping\n",
        "print(\"Our vocabulary\", count_vect.vocabulary_)\n",
        "\n",
        "# get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"it is not so long ago that ipsum gone\"])\n",
        "print(\"Bow representation for 'it is not so long ago that ipsum gone'\", temp.toarray())\n",
        "# quick pre-process step\n",
        "print(processed_docs)\n",
        "processed_docs2 = [doc.lower().replace(\".\", \"\") for doc in processed_docs]\n",
        "\n",
        "print(processed_docs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRfLPDVMk4df",
        "outputId": "5d96345c-3d40-4c66-9e7d-94e04d1336de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our vocabulary {'it': 10, 'is': 6, 'long': 13, 'stablished': 20, 'fact': 0, 'that': 23, 'it is': 11, 'is long': 7, 'long stablished': 14, 'stablished fact': 21, 'fact that': 1, 'that is': 24, 'it is long': 12, 'is long stablished': 8, 'long stablished fact': 15, 'stablished fact that': 22, 'fact that is': 2, 'lorem': 16, 'ipsum': 3, 'simply': 19, 'lorem ipsum': 17, 'ipsum is': 4, 'is simply': 9, 'lorem ipsum is': 18, 'ipsum is simply': 5}\n",
            "Bow representation for 'it is not so long ago that ipsum gone' [[0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0]]\n",
            "['It is a long stablished fact that is', 'Lorem Ipsum is simply']\n",
            "['it is a long stablished fact that is', 'lorem ipsum is simply']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "no_aUdIbxzec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_documents = [\"boys are humans\", \"girls are humans\", \"boy and girls are people\", \"boys love dogs\", \"dogs bark people\"]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert a collection of raw documents into a matrix of TF-IDF features\n",
        "tfidf = TfidfVectorizer()\n",
        "bow_rep_tfidf = tfidf.fit_transform(processed_documents)\n",
        "\n",
        "# IDF for all words in the vocabulary\n",
        "print(\"IDF for all words in the vocabulary\\n\", tfidf.idf_)\n",
        "\n",
        "# All words int the vocabulary\n",
        "print(\"All words int the vocabulary\\n\", tfidf.get_feature_names_out())\n",
        "\n",
        "temp = tfidf.transform([\"boys and girls love dogs\"])\n",
        "print(\"Tfidf representation for 'boys and girls love dogs'\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5wByTm9x2xg",
        "outputId": "4e4fdd28-0e26-43fd-d289-ee08c9020800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDF for all words in the vocabulary\n",
            " [2.09861229 1.40546511 2.09861229 2.09861229 1.69314718 1.69314718\n",
            " 1.69314718 1.69314718 2.09861229 1.69314718]\n",
            "All words int the vocabulary\n",
            " ['and' 'are' 'bark' 'boy' 'boys' 'dogs' 'girls' 'humans' 'love' 'people']\n",
            "Tfidf representation for 'boys and girls love dogs' [[0.50297966 0.         0.         0.         0.40580082 0.40580082\n",
            "  0.40580082 0.         0.50297966 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distributed Representations"
      ],
      "metadata": {
        "id": "Lz0jRVKIEfWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embeddings"
      ],
      "metadata": {
        "id": "2xAfWSRFe34V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "O5tJ4phsbnYy",
        "outputId": "6a117e8c-9c42-4ea7-d925-8ddc01603f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-942c3eba-b845-4dc8-8c90-35914ae4e4c7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-942c3eba-b845-4dc8-8c90-35914ae4e4c7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "\n",
        "dataset_name = 'leadbest/googlenewsvectorsnegative300'\n",
        "destination_path = 'archive'\n",
        "\n",
        "kaggle.api.dataset_download_files(dataset_name, path=destination_path, unzip=True)"
      ],
      "metadata": {
        "id": "WSIfdJvPL-tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4#7-methods-like-most_similar-wmdistance-doesnt_match-similarity--others-moved-to-keyedvectors\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "pretrainedPath = \"/content/archive/GoogleNews-vectors-negative300.bin\"\n",
        "w2v_model = KeyedVectors.load_word2vec_format(pretrainedPath, binary=True)\n",
        "\n",
        "print(\"done loading Word2Vec\")\n",
        "print(len(w2v_model.key_to_index)) # Number of words in the vocabulary."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UKaRG8XE0kX",
        "outputId": "795e4c2f-9d9e-4f19-8fe9-a529da06fc6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done loading Word2Vec\n",
            "3000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.most_similar('effort')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyME9sqjJtDc",
        "outputId": "5a346d3d-0a44-4773-dab4-ec393f9d38fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('efforts', 0.7569211721420288),\n",
              " ('attempt', 0.6435876488685608),\n",
              " ('ef_fort', 0.5995086431503296),\n",
              " ('concerted_effort', 0.5943657755851746),\n",
              " ('endeavor', 0.5759328007698059),\n",
              " ('eff_ort', 0.5580997467041016),\n",
              " ('initiative', 0.5448550581932068),\n",
              " ('eff_orts', 0.5061603784561157),\n",
              " ('Effort', 0.5019460320472717),\n",
              " ('attempts', 0.4948119819164276)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector representation for a word\n",
        "w2v_model['effort'].shape\n",
        "w2v_model['effort']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaHNVPEGPHk-",
        "outputId": "8d72e833-2d0c-4ce8-ec91-521b8ba6fd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.56250000e-01,  2.02148438e-01, -8.30078125e-02,  7.32421875e-02,\n",
              "       -1.70898438e-02,  1.27563477e-02,  1.92382812e-01, -2.04101562e-01,\n",
              "       -1.63574219e-02,  6.05468750e-02, -1.03027344e-01, -8.74023438e-02,\n",
              "        1.98974609e-02, -1.78710938e-01, -1.01562500e-01, -1.15722656e-01,\n",
              "        9.61914062e-02,  9.61914062e-02,  1.71875000e-01, -3.39355469e-02,\n",
              "        6.13403320e-03,  1.45507812e-01,  4.15039062e-02, -9.47265625e-02,\n",
              "       -1.13769531e-01, -7.17773438e-02, -1.01562500e-01, -5.98144531e-02,\n",
              "       -8.10546875e-02,  2.51464844e-02,  1.03515625e-01, -1.77734375e-01,\n",
              "        2.05078125e-01, -1.04492188e-01,  2.36328125e-01,  2.23632812e-01,\n",
              "        2.65625000e-01, -6.40869141e-03,  2.18750000e-01,  2.19726562e-01,\n",
              "        2.14843750e-01,  5.88378906e-02, -9.32617188e-02, -6.34765625e-02,\n",
              "       -1.50390625e-01, -9.13085938e-02, -2.12890625e-01, -4.83398438e-02,\n",
              "       -1.25976562e-01,  2.38037109e-02,  1.91406250e-01,  1.74804688e-01,\n",
              "        9.66796875e-02,  9.17968750e-02,  1.42578125e-01,  8.93554688e-02,\n",
              "        1.69921875e-01, -9.91210938e-02, -1.22558594e-01,  5.44433594e-02,\n",
              "        3.73535156e-02,  1.18408203e-02, -4.04296875e-01, -2.51953125e-01,\n",
              "       -4.66308594e-02, -5.54199219e-02, -1.09100342e-03,  1.10351562e-01,\n",
              "       -5.68847656e-02, -7.95898438e-02, -8.44726562e-02, -8.25195312e-02,\n",
              "       -7.22656250e-02,  4.57763672e-03,  7.95898438e-02,  8.91113281e-03,\n",
              "        1.91406250e-01, -6.25000000e-02,  8.05664062e-02, -1.04980469e-01,\n",
              "       -8.74023438e-02, -2.79541016e-02,  6.64062500e-02, -1.44531250e-01,\n",
              "        7.76367188e-02,  5.24902344e-02, -8.10546875e-02,  5.10253906e-02,\n",
              "        9.42382812e-02,  9.22851562e-02,  8.49609375e-02,  3.79943848e-03,\n",
              "        8.39843750e-02, -8.39843750e-02,  1.18652344e-01, -8.10546875e-02,\n",
              "       -2.07031250e-01,  1.53320312e-01, -1.25000000e-01,  1.30859375e-01,\n",
              "        9.76562500e-03,  9.27734375e-02,  1.15356445e-02,  7.95898438e-02,\n",
              "        1.44653320e-02,  1.29882812e-01, -1.39648438e-01, -2.04101562e-01,\n",
              "        4.69970703e-03,  9.96093750e-02, -2.22656250e-01, -1.57928467e-03,\n",
              "       -7.95898438e-02,  6.34765625e-02, -8.78906250e-02,  1.15234375e-01,\n",
              "       -7.03125000e-02,  2.04086304e-04, -2.80761719e-02,  9.76562500e-02,\n",
              "       -9.86328125e-02,  1.89453125e-01, -4.51660156e-02,  3.32031250e-02,\n",
              "       -6.73828125e-02, -1.48315430e-02,  6.73828125e-02, -1.61132812e-01,\n",
              "       -3.56445312e-02,  1.58203125e-01, -8.83789062e-02,  2.16064453e-02,\n",
              "        4.44335938e-02, -5.05371094e-02,  6.29882812e-02, -8.10546875e-02,\n",
              "        7.27539062e-02, -7.03125000e-02, -1.00097656e-01, -3.27148438e-02,\n",
              "        1.35742188e-01, -5.37109375e-02, -5.24902344e-02, -1.01074219e-01,\n",
              "        7.12890625e-02, -9.47265625e-02,  8.30078125e-03,  4.24804688e-02,\n",
              "       -1.43432617e-02,  7.27539062e-02,  1.19140625e-01, -9.96093750e-02,\n",
              "        4.02832031e-02,  2.85156250e-01,  2.27539062e-01, -1.03027344e-01,\n",
              "        2.32421875e-01, -1.86767578e-02, -1.51977539e-02, -1.02050781e-01,\n",
              "        1.21307373e-03,  1.77734375e-01,  2.32421875e-01,  4.80957031e-02,\n",
              "       -1.24023438e-01, -3.26171875e-01,  3.80859375e-01, -1.59179688e-01,\n",
              "        2.79296875e-01, -3.75976562e-02,  9.37500000e-02,  5.76171875e-02,\n",
              "       -2.55859375e-01, -1.13769531e-01,  1.98242188e-01, -1.17187500e-01,\n",
              "        1.43554688e-01,  1.02539062e-01,  1.18652344e-01,  2.08740234e-02,\n",
              "       -1.04003906e-01, -1.00097656e-01,  6.93359375e-02,  8.15429688e-02,\n",
              "       -6.22558594e-03, -1.57226562e-01, -6.39648438e-02,  1.43432617e-02,\n",
              "        5.44433594e-02, -1.45507812e-01, -1.24023438e-01, -1.58203125e-01,\n",
              "        2.89062500e-01,  9.71679688e-02, -4.74609375e-01, -5.15136719e-02,\n",
              "        2.08007812e-01,  2.59765625e-01, -1.73828125e-01, -1.27929688e-01,\n",
              "        9.13085938e-02,  2.53906250e-01,  1.03027344e-01,  5.90820312e-02,\n",
              "        1.96289062e-01,  1.21459961e-02, -1.05468750e-01, -1.05468750e-01,\n",
              "        6.49414062e-02,  1.60156250e-01, -1.66015625e-01,  8.88671875e-02,\n",
              "       -3.49609375e-01,  2.12890625e-01, -3.49121094e-02,  8.59375000e-02,\n",
              "        5.37109375e-02,  3.22265625e-01, -1.41601562e-01,  8.05664062e-02,\n",
              "       -1.39648438e-01, -1.29882812e-01,  6.83593750e-02,  1.15722656e-01,\n",
              "       -1.22558594e-01,  1.51367188e-01,  2.13867188e-01, -5.12695312e-02,\n",
              "        2.61718750e-01, -1.25000000e-01,  1.32812500e-01, -2.45361328e-02,\n",
              "       -8.69140625e-02, -1.52343750e-01, -1.17675781e-01, -6.10351562e-02,\n",
              "       -1.96289062e-01,  3.51562500e-02,  2.96630859e-02, -1.58203125e-01,\n",
              "       -1.58203125e-01,  1.50390625e-01,  1.64062500e-01, -1.64062500e-01,\n",
              "       -5.17578125e-02,  2.13867188e-01,  1.77734375e-01,  1.73828125e-01,\n",
              "        1.83593750e-01,  4.68750000e-02, -2.06054688e-01, -1.69677734e-02,\n",
              "       -1.08398438e-01,  6.17675781e-02,  1.12304688e-01,  1.44042969e-02,\n",
              "        2.63671875e-01, -5.20019531e-02, -5.32226562e-02, -2.74658203e-02,\n",
              "       -9.76562500e-02,  2.45117188e-01,  5.59082031e-02,  1.13769531e-01,\n",
              "       -4.54101562e-02, -1.26342773e-02, -2.46582031e-02, -1.29882812e-01,\n",
              "       -3.43750000e-01,  1.21582031e-01, -9.57031250e-02,  1.07421875e-02,\n",
              "        1.98242188e-01,  1.41601562e-01,  2.84423828e-02, -9.58251953e-03,\n",
              "       -8.85009766e-03, -1.98242188e-01, -3.83377075e-04,  1.58203125e-01,\n",
              "       -1.26953125e-01, -2.20703125e-01,  1.58203125e-01,  2.63671875e-01,\n",
              "       -2.65625000e-01, -1.24511719e-01, -1.84326172e-02,  7.61718750e-02,\n",
              "        2.24609375e-01, -1.01562500e-01, -3.35937500e-01, -1.76757812e-01,\n",
              "       -6.25000000e-02,  6.80541992e-03, -8.98437500e-02,  6.88476562e-02,\n",
              "        5.93261719e-02,  6.64062500e-02, -1.38671875e-01, -7.27539062e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZKkKMiHgWq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}