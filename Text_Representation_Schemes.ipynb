{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Vectorization Approaches"
      ],
      "metadata": {
        "id": "y2wIcLp8yLNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Representation Schemes"
      ],
      "metadata": {
        "id": "XMeK4ImG4BvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding"
      ],
      "metadata": {
        "id": "6O07ryEF4IOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbLwJC9Xw1iM",
        "outputId": "8cd0fe40-fa70-4736-e29e-1e4cfc3ce989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'It': 1, 'is': 9, 'a': 3, 'long': 4, 'stablished': 5, 'fact': 6, 'that': 7, 'Lorem': 8, 'Ipsum': 9, 'simply': 10}\n",
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "count = 0\n",
        "vocab = {}\n",
        "processed_docs = [\n",
        "    \"It is a long stablished fact that is\", \n",
        "    \"Lorem Ipsum is simply\"\n",
        "    ]\n",
        "\n",
        "for doc in processed_docs:\n",
        "  for word in doc.split():\n",
        "    if word not in vocab:\n",
        "      count += 1\n",
        "    vocab[word] = count\n",
        "\n",
        "print(vocab) \n",
        "print(len(vocab))\n",
        "\n",
        "def get_onehot_vector(somestring):\n",
        "  onehot_encoded = []\n",
        "  for word in somestring.split():\n",
        "    temp = [0]*len(vocab)\n",
        "    if word in vocab:\n",
        "      temp[vocab[word]-1]=1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
        "    onehot_encoded.append(temp)\n",
        "  return onehot_encoded\n",
        "\n",
        "get_onehot_vector(processed_docs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of Words"
      ],
      "metadata": {
        "id": "NCU7PD4e4OnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "# Build a BOW representation for the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "# Look at the vocabulary mapping\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary)\n",
        "\n",
        "# See the BOW representation for first 2 documents\n",
        "print(\"BoW representation for 'It is a long stablished fact that is': \", bow_rep[0].toarray())\n",
        "print(\"BoW representation for 'Loren Ipsum is simply': \", bow_rep[1].toarray())\n",
        "\n",
        "# Get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"long stablished Loren is is long\"])\n",
        "print(\"long stablished Loren is\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgcShvvmk24s",
        "outputId": "5bf1c165-8f76-417c-d489-7e12434afddb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our vocabulary:  None\n",
            "BoW representation for 'It is a long stablished fact that is':  [[1 0 2 1 1 0 0 1 1]]\n",
            "BoW representation for 'Loren Ipsum is simply':  [[0 1 1 0 0 1 1 0 0]]\n",
            "long stablished Loren is [[0 0 2 0 2 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of N-grams"
      ],
      "metadata": {
        "id": "QvwWGnELxpJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# quick pre-process step\n",
        "print(processed_docs)\n",
        "processed_docs2 = [doc.lower().replace(\".\", \"\") for doc in processed_docs]\n",
        "\n",
        "print(processed_docs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21cb243-ab26-4d47-c623-49a9d3e4efd7",
        "id": "gBsQBxTjxvgN"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It is a long stablished fact that is', 'Lorem Ipsum is simply']\n",
            "['it is a long stablished fact that is', 'lorem ipsum is simply']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance with uni, bi, and trigrams\n",
        "count_vect = CountVectorizer(ngram_range=(1, 3))\n",
        "\n",
        "# build a bow representation of the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs2)\n",
        "\n",
        "# Look at the vocabulary mapping\n",
        "print(\"Our vocabulary\", count_vect.vocabulary_)\n",
        "\n",
        "# get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"it is not so long ago that ipsum gone\"])\n",
        "print(\"Bow representation for 'it is not so long ago that ipsum gone'\", temp.toarray())\n",
        "# quick pre-process step\n",
        "print(processed_docs)\n",
        "processed_docs2 = [doc.lower().replace(\".\", \"\") for doc in processed_docs]\n",
        "\n",
        "print(processed_docs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRfLPDVMk4df",
        "outputId": "5d96345c-3d40-4c66-9e7d-94e04d1336de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our vocabulary {'it': 10, 'is': 6, 'long': 13, 'stablished': 20, 'fact': 0, 'that': 23, 'it is': 11, 'is long': 7, 'long stablished': 14, 'stablished fact': 21, 'fact that': 1, 'that is': 24, 'it is long': 12, 'is long stablished': 8, 'long stablished fact': 15, 'stablished fact that': 22, 'fact that is': 2, 'lorem': 16, 'ipsum': 3, 'simply': 19, 'lorem ipsum': 17, 'ipsum is': 4, 'is simply': 9, 'lorem ipsum is': 18, 'ipsum is simply': 5}\n",
            "Bow representation for 'it is not so long ago that ipsum gone' [[0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0]]\n",
            "['It is a long stablished fact that is', 'Lorem Ipsum is simply']\n",
            "['it is a long stablished fact that is', 'lorem ipsum is simply']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "no_aUdIbxzec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_documents = [\"boys are humans\", \"girls are humans\", \"boy and girls are people\", \"boys love dogs\", \"dogs bark people\"]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert a collection of raw documents into a matrix of TF-IDF features\n",
        "tfidf = TfidfVectorizer()\n",
        "bow_rep_tfidf = tfidf.fit_transform(processed_documents)\n",
        "\n",
        "# IDF for all words in the vocabulary\n",
        "print(\"IDF for all words in the vocabulary\\n\", tfidf.idf_)\n",
        "\n",
        "# All words int the vocabulary\n",
        "print(\"All words int the vocabulary\\n\", tfidf.get_feature_names_out())\n",
        "\n",
        "temp = tfidf.transform([\"boys and girls love dogs\"])\n",
        "print(\"Tfidf representation for 'boys and girls love dogs'\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5wByTm9x2xg",
        "outputId": "4e4fdd28-0e26-43fd-d289-ee08c9020800"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDF for all words in the vocabulary\n",
            " [2.09861229 1.40546511 2.09861229 2.09861229 1.69314718 1.69314718\n",
            " 1.69314718 1.69314718 2.09861229 1.69314718]\n",
            "All words int the vocabulary\n",
            " ['and' 'are' 'bark' 'boy' 'boys' 'dogs' 'girls' 'humans' 'love' 'people']\n",
            "Tfidf representation for 'boys and girls love dogs' [[0.50297966 0.         0.         0.         0.40580082 0.40580082\n",
            "  0.40580082 0.         0.50297966 0.        ]]\n"
          ]
        }
      ]
    }
  ]
}