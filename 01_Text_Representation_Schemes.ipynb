{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Vectorization Approaches"
      ],
      "metadata": {
        "id": "y2wIcLp8yLNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Representation Schemes"
      ],
      "metadata": {
        "id": "XMeK4ImG4BvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding"
      ],
      "metadata": {
        "id": "6O07ryEF4IOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbLwJC9Xw1iM",
        "outputId": "3bdafeba-2220-4abf-f683-dc2a794d8901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'It': 1, 'is': 9, 'a': 3, 'long': 4, 'stablished': 5, 'fact': 6, 'that': 7, 'Lorem': 8, 'Ipsum': 9, 'simply': 10}\n",
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "count = 0\n",
        "vocab = {}\n",
        "processed_docs = [\n",
        "    \"It is a long stablished fact that is\", \n",
        "    \"Lorem Ipsum is simply\"\n",
        "    ]\n",
        "\n",
        "for doc in processed_docs:\n",
        "  for word in doc.split():\n",
        "    if word not in vocab:\n",
        "      count += 1\n",
        "    vocab[word] = count\n",
        "\n",
        "print(vocab) \n",
        "print(len(vocab))\n",
        "\n",
        "def get_onehot_vector(somestring):\n",
        "  onehot_encoded = []\n",
        "  for word in somestring.split():\n",
        "    temp = [0]*len(vocab)\n",
        "    if word in vocab:\n",
        "      temp[vocab[word]-1]=1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
        "    onehot_encoded.append(temp)\n",
        "  return onehot_encoded\n",
        "\n",
        "get_onehot_vector(processed_docs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of Words"
      ],
      "metadata": {
        "id": "NCU7PD4e4OnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "# Build a BOW representation for the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "# Look at the vocabulary mapping\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary)\n",
        "\n",
        "# See the BOW representation for first 2 documents\n",
        "print(\"BoW representation for 'It is a long stablished fact that is': \", bow_rep[0].toarray())\n",
        "print(\"BoW representation for 'Loren Ipsum is simply': \", bow_rep[1].toarray())\n",
        "\n",
        "# Get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"long stablished Loren is is long\"])\n",
        "print(\"long stablished Loren is\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgcShvvmk24s",
        "outputId": "51c02a06-a1c5-435a-b8cf-6d2c762a4f30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our vocabulary:  None\n",
            "BoW representation for 'It is a long stablished fact that is':  [[1 0 2 1 1 0 0 1 1]]\n",
            "BoW representation for 'Loren Ipsum is simply':  [[0 1 1 0 0 1 1 0 0]]\n",
            "long stablished Loren is [[0 0 2 0 2 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of N-grams"
      ],
      "metadata": {
        "id": "QvwWGnELxpJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# quick pre-process step\n",
        "print(processed_docs)\n",
        "processed_docs2 = [doc.lower().replace(\".\", \"\") for doc in processed_docs]\n",
        "\n",
        "print(processed_docs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d082e205-8e4e-4fd2-b291-3b9e4a121d80",
        "id": "gBsQBxTjxvgN"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It is a long stablished fact that is', 'Lorem Ipsum is simply']\n",
            "['it is a long stablished fact that is', 'lorem ipsum is simply']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance with uni, bi, and trigrams\n",
        "count_vect = CountVectorizer(ngram_range=(1, 3))\n",
        "\n",
        "# build a bow representation of the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs2)\n",
        "\n",
        "# Look at the vocabulary mapping\n",
        "print(\"Our vocabulary\", count_vect.vocabulary_)\n",
        "\n",
        "# get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"it is not so long ago that ipsum gone\"])\n",
        "print(\"Bow representation for 'it is not so long ago that ipsum gone'\", temp.toarray())\n",
        "# quick pre-process step\n",
        "print(processed_docs)\n",
        "processed_docs2 = [doc.lower().replace(\".\", \"\") for doc in processed_docs]\n",
        "\n",
        "print(processed_docs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRfLPDVMk4df",
        "outputId": "112ac524-5e1a-470b-f3fa-d1277416420c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our vocabulary {'it': 10, 'is': 6, 'long': 13, 'stablished': 20, 'fact': 0, 'that': 23, 'it is': 11, 'is long': 7, 'long stablished': 14, 'stablished fact': 21, 'fact that': 1, 'that is': 24, 'it is long': 12, 'is long stablished': 8, 'long stablished fact': 15, 'stablished fact that': 22, 'fact that is': 2, 'lorem': 16, 'ipsum': 3, 'simply': 19, 'lorem ipsum': 17, 'ipsum is': 4, 'is simply': 9, 'lorem ipsum is': 18, 'ipsum is simply': 5}\n",
            "Bow representation for 'it is not so long ago that ipsum gone' [[0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0]]\n",
            "['It is a long stablished fact that is', 'Lorem Ipsum is simply']\n",
            "['it is a long stablished fact that is', 'lorem ipsum is simply']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "no_aUdIbxzec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_documents = [\"boys are humans\", \"girls are humans\", \"boy and girls are people\", \"boys love dogs\", \"dogs bark people\"]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert a collection of raw documents into a matrix of TF-IDF features\n",
        "tfidf = TfidfVectorizer()\n",
        "bow_rep_tfidf = tfidf.fit_transform(processed_documents)\n",
        "\n",
        "# IDF for all words in the vocabulary\n",
        "print(\"IDF for all words in the vocabulary\\n\", tfidf.idf_)\n",
        "\n",
        "# All words int the vocabulary\n",
        "print(\"All words int the vocabulary\\n\", tfidf.get_feature_names_out())\n",
        "\n",
        "temp = tfidf.transform([\"boys and girls love dogs\"])\n",
        "print(\"Tfidf representation for 'boys and girls love dogs'\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5wByTm9x2xg",
        "outputId": "b37af0ef-976f-4f93-ff3a-8b7649157cfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDF for all words in the vocabulary\n",
            " [2.09861229 1.40546511 2.09861229 2.09861229 1.69314718 1.69314718\n",
            " 1.69314718 1.69314718 2.09861229 1.69314718]\n",
            "All words int the vocabulary\n",
            " ['and' 'are' 'bark' 'boy' 'boys' 'dogs' 'girls' 'humans' 'love' 'people']\n",
            "Tfidf representation for 'boys and girls love dogs' [[0.50297966 0.         0.         0.         0.40580082 0.40580082\n",
            "  0.40580082 0.         0.50297966 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distributed Representations"
      ],
      "metadata": {
        "id": "Lz0jRVKIEfWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embeddings"
      ],
      "metadata": {
        "id": "2xAfWSRFe34V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "O5tJ4phsbnYy",
        "outputId": "49f8095d-a462-4dcd-a624-54d142195ba2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e8421c81-5741-48b6-88a2-b35f5f7603b4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e8421c81-5741-48b6-88a2-b35f5f7603b4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "\n",
        "dataset_name = 'leadbest/googlenewsvectorsnegative300'\n",
        "destination_path = 'archive'\n",
        "\n",
        "kaggle.api.dataset_download_files(dataset_name, path=destination_path, unzip=True)"
      ],
      "metadata": {
        "id": "WSIfdJvPL-tE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4#7-methods-like-most_similar-wmdistance-doesnt_match-similarity--others-moved-to-keyedvectors\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "pretrainedPath = \"/content/archive/GoogleNews-vectors-negative300.bin\"\n",
        "w2v_model = KeyedVectors.load_word2vec_format(pretrainedPath, binary=True)\n",
        "\n",
        "print(\"done loading Word2Vec\")\n",
        "print(len(w2v_model.key_to_index)) # Number of words in the vocabulary."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UKaRG8XE0kX",
        "outputId": "035d4cb0-7725-47fc-9646-df5a2311f26e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done loading Word2Vec\n",
            "3000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.most_similar('effort')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyME9sqjJtDc",
        "outputId": "21feaf11-9289-4b7c-8675-b7958fcf3906"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('efforts', 0.7569211721420288),\n",
              " ('attempt', 0.6435876488685608),\n",
              " ('ef_fort', 0.5995086431503296),\n",
              " ('concerted_effort', 0.5943657755851746),\n",
              " ('endeavor', 0.5759328007698059),\n",
              " ('eff_ort', 0.5580997467041016),\n",
              " ('initiative', 0.5448550581932068),\n",
              " ('eff_orts', 0.5061603784561157),\n",
              " ('Effort', 0.5019460320472717),\n",
              " ('attempts', 0.4948119819164276)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector representation for a word\n",
        "w2v_model['effort'].shape\n",
        "w2v_model['effort']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaHNVPEGPHk-",
        "outputId": "0ae161f9-bd03-4556-8663-933012ca7daa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.56250000e-01,  2.02148438e-01, -8.30078125e-02,  7.32421875e-02,\n",
              "       -1.70898438e-02,  1.27563477e-02,  1.92382812e-01, -2.04101562e-01,\n",
              "       -1.63574219e-02,  6.05468750e-02, -1.03027344e-01, -8.74023438e-02,\n",
              "        1.98974609e-02, -1.78710938e-01, -1.01562500e-01, -1.15722656e-01,\n",
              "        9.61914062e-02,  9.61914062e-02,  1.71875000e-01, -3.39355469e-02,\n",
              "        6.13403320e-03,  1.45507812e-01,  4.15039062e-02, -9.47265625e-02,\n",
              "       -1.13769531e-01, -7.17773438e-02, -1.01562500e-01, -5.98144531e-02,\n",
              "       -8.10546875e-02,  2.51464844e-02,  1.03515625e-01, -1.77734375e-01,\n",
              "        2.05078125e-01, -1.04492188e-01,  2.36328125e-01,  2.23632812e-01,\n",
              "        2.65625000e-01, -6.40869141e-03,  2.18750000e-01,  2.19726562e-01,\n",
              "        2.14843750e-01,  5.88378906e-02, -9.32617188e-02, -6.34765625e-02,\n",
              "       -1.50390625e-01, -9.13085938e-02, -2.12890625e-01, -4.83398438e-02,\n",
              "       -1.25976562e-01,  2.38037109e-02,  1.91406250e-01,  1.74804688e-01,\n",
              "        9.66796875e-02,  9.17968750e-02,  1.42578125e-01,  8.93554688e-02,\n",
              "        1.69921875e-01, -9.91210938e-02, -1.22558594e-01,  5.44433594e-02,\n",
              "        3.73535156e-02,  1.18408203e-02, -4.04296875e-01, -2.51953125e-01,\n",
              "       -4.66308594e-02, -5.54199219e-02, -1.09100342e-03,  1.10351562e-01,\n",
              "       -5.68847656e-02, -7.95898438e-02, -8.44726562e-02, -8.25195312e-02,\n",
              "       -7.22656250e-02,  4.57763672e-03,  7.95898438e-02,  8.91113281e-03,\n",
              "        1.91406250e-01, -6.25000000e-02,  8.05664062e-02, -1.04980469e-01,\n",
              "       -8.74023438e-02, -2.79541016e-02,  6.64062500e-02, -1.44531250e-01,\n",
              "        7.76367188e-02,  5.24902344e-02, -8.10546875e-02,  5.10253906e-02,\n",
              "        9.42382812e-02,  9.22851562e-02,  8.49609375e-02,  3.79943848e-03,\n",
              "        8.39843750e-02, -8.39843750e-02,  1.18652344e-01, -8.10546875e-02,\n",
              "       -2.07031250e-01,  1.53320312e-01, -1.25000000e-01,  1.30859375e-01,\n",
              "        9.76562500e-03,  9.27734375e-02,  1.15356445e-02,  7.95898438e-02,\n",
              "        1.44653320e-02,  1.29882812e-01, -1.39648438e-01, -2.04101562e-01,\n",
              "        4.69970703e-03,  9.96093750e-02, -2.22656250e-01, -1.57928467e-03,\n",
              "       -7.95898438e-02,  6.34765625e-02, -8.78906250e-02,  1.15234375e-01,\n",
              "       -7.03125000e-02,  2.04086304e-04, -2.80761719e-02,  9.76562500e-02,\n",
              "       -9.86328125e-02,  1.89453125e-01, -4.51660156e-02,  3.32031250e-02,\n",
              "       -6.73828125e-02, -1.48315430e-02,  6.73828125e-02, -1.61132812e-01,\n",
              "       -3.56445312e-02,  1.58203125e-01, -8.83789062e-02,  2.16064453e-02,\n",
              "        4.44335938e-02, -5.05371094e-02,  6.29882812e-02, -8.10546875e-02,\n",
              "        7.27539062e-02, -7.03125000e-02, -1.00097656e-01, -3.27148438e-02,\n",
              "        1.35742188e-01, -5.37109375e-02, -5.24902344e-02, -1.01074219e-01,\n",
              "        7.12890625e-02, -9.47265625e-02,  8.30078125e-03,  4.24804688e-02,\n",
              "       -1.43432617e-02,  7.27539062e-02,  1.19140625e-01, -9.96093750e-02,\n",
              "        4.02832031e-02,  2.85156250e-01,  2.27539062e-01, -1.03027344e-01,\n",
              "        2.32421875e-01, -1.86767578e-02, -1.51977539e-02, -1.02050781e-01,\n",
              "        1.21307373e-03,  1.77734375e-01,  2.32421875e-01,  4.80957031e-02,\n",
              "       -1.24023438e-01, -3.26171875e-01,  3.80859375e-01, -1.59179688e-01,\n",
              "        2.79296875e-01, -3.75976562e-02,  9.37500000e-02,  5.76171875e-02,\n",
              "       -2.55859375e-01, -1.13769531e-01,  1.98242188e-01, -1.17187500e-01,\n",
              "        1.43554688e-01,  1.02539062e-01,  1.18652344e-01,  2.08740234e-02,\n",
              "       -1.04003906e-01, -1.00097656e-01,  6.93359375e-02,  8.15429688e-02,\n",
              "       -6.22558594e-03, -1.57226562e-01, -6.39648438e-02,  1.43432617e-02,\n",
              "        5.44433594e-02, -1.45507812e-01, -1.24023438e-01, -1.58203125e-01,\n",
              "        2.89062500e-01,  9.71679688e-02, -4.74609375e-01, -5.15136719e-02,\n",
              "        2.08007812e-01,  2.59765625e-01, -1.73828125e-01, -1.27929688e-01,\n",
              "        9.13085938e-02,  2.53906250e-01,  1.03027344e-01,  5.90820312e-02,\n",
              "        1.96289062e-01,  1.21459961e-02, -1.05468750e-01, -1.05468750e-01,\n",
              "        6.49414062e-02,  1.60156250e-01, -1.66015625e-01,  8.88671875e-02,\n",
              "       -3.49609375e-01,  2.12890625e-01, -3.49121094e-02,  8.59375000e-02,\n",
              "        5.37109375e-02,  3.22265625e-01, -1.41601562e-01,  8.05664062e-02,\n",
              "       -1.39648438e-01, -1.29882812e-01,  6.83593750e-02,  1.15722656e-01,\n",
              "       -1.22558594e-01,  1.51367188e-01,  2.13867188e-01, -5.12695312e-02,\n",
              "        2.61718750e-01, -1.25000000e-01,  1.32812500e-01, -2.45361328e-02,\n",
              "       -8.69140625e-02, -1.52343750e-01, -1.17675781e-01, -6.10351562e-02,\n",
              "       -1.96289062e-01,  3.51562500e-02,  2.96630859e-02, -1.58203125e-01,\n",
              "       -1.58203125e-01,  1.50390625e-01,  1.64062500e-01, -1.64062500e-01,\n",
              "       -5.17578125e-02,  2.13867188e-01,  1.77734375e-01,  1.73828125e-01,\n",
              "        1.83593750e-01,  4.68750000e-02, -2.06054688e-01, -1.69677734e-02,\n",
              "       -1.08398438e-01,  6.17675781e-02,  1.12304688e-01,  1.44042969e-02,\n",
              "        2.63671875e-01, -5.20019531e-02, -5.32226562e-02, -2.74658203e-02,\n",
              "       -9.76562500e-02,  2.45117188e-01,  5.59082031e-02,  1.13769531e-01,\n",
              "       -4.54101562e-02, -1.26342773e-02, -2.46582031e-02, -1.29882812e-01,\n",
              "       -3.43750000e-01,  1.21582031e-01, -9.57031250e-02,  1.07421875e-02,\n",
              "        1.98242188e-01,  1.41601562e-01,  2.84423828e-02, -9.58251953e-03,\n",
              "       -8.85009766e-03, -1.98242188e-01, -3.83377075e-04,  1.58203125e-01,\n",
              "       -1.26953125e-01, -2.20703125e-01,  1.58203125e-01,  2.63671875e-01,\n",
              "       -2.65625000e-01, -1.24511719e-01, -1.84326172e-02,  7.61718750e-02,\n",
              "        2.24609375e-01, -1.01562500e-01, -3.35937500e-01, -1.76757812e-01,\n",
              "       -6.25000000e-02,  6.80541992e-03, -8.98437500e-02,  6.88476562e-02,\n",
              "        5.93261719e-02,  6.64062500e-02, -1.38671875e-01, -7.27539062e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Own Embeddings\n",
        "There are 2 architectural variants when it comes to word2vec approach:\n",
        "- Continuous Bag of Words (CBOW): Builds a language model that predicts the center word given the context\n",
        "- SkipGram: Builds a language model that predicts the context given the center word\n"
      ],
      "metadata": {
        "id": "M7_jnPN9ATeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By default gensim library uses SkipGram\n",
        "\n",
        "# import dataset of text to train the model\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "print(common_texts)\n",
        "custom_model = Word2Vec(common_texts, vector_size=10, window=5, min_count=1, workers=4)\n",
        "\n",
        "# save the model\n",
        "custom_model.save(\"custom_model.w2v\")\n",
        "# inspect the model by looking for the most similar words for a test word\n",
        "print(custom_model.wv.most_similar('computer', topn=5))\n",
        "print(custom_model.wv[\"computer\"])\n"
      ],
      "metadata": {
        "id": "ZZKkKMiHgWq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9d4498-c73d-48e2-f7a6-d7137e40105c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n",
            "[('eps', 0.2914133667945862), ('trees', 0.05541810393333435), ('minors', 0.042647670954465866), ('survey', -0.02176341600716114), ('interface', -0.15233567357063293)]\n",
            "[ 0.0163195   0.00189972  0.03474648  0.00217841  0.09621626  0.05062076\n",
            " -0.08919986 -0.0704361   0.00901718  0.06394394]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative dataset\n",
        "\n",
        "with open(\"maria_chucena.txt\", \"r\") as file:\n",
        "  text = file.read()\n",
        "\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2BUKljID8Pl",
        "outputId": "d6d89ae1-c04e-44d5-ee5b-fbebc3d5907e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "María Chucena, ¿tú techas tu choza\n",
            "O techas la ajena? - No techo mi choza\n",
            "Ni techo la ajena, que tec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Tokenize the sentences and store them as a list of lists\n",
        "sentences = re.split(r'\\n', text)  # Split the text into sentences\n",
        "tokenized_texts = [re.findall(r'\\w+', sentence.lower()) for sentence in sentences if sentence.strip()]\n",
        "tokenized_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IZCJYNbD9UM",
        "outputId": "4e080aa9-b17b-4e9b-9f78-46f204f24171"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['maría', 'chucena', 'tú', 'techas', 'tu', 'choza'],\n",
              " ['o', 'techas', 'la', 'ajena', 'no', 'techo', 'mi', 'choza'],\n",
              " ['ni', 'techo', 'la', 'ajena', 'que', 'techo', 'la', 'choza'],\n",
              " ['de', 'maría', 'chucena'],\n",
              " ['maría', 'chucena', 'tú', 'techas', 'tu', 'choza'],\n",
              " ['o', 'techas', 'la', 'ajena', 'no', 'techo', 'mi', 'choza'],\n",
              " ['ni', 'techo', 'la', 'ajena', 'que', 'techo', 'la', 'choza'],\n",
              " ['de', 'maría', 'chucena'],\n",
              " ['no', 'techo', 'mi', 'choza'],\n",
              " ['ni', 'techo', 'la', 'ajena', 'que', 'techo', 'la', 'choza'],\n",
              " ['de', 'maría', 'chucena'],\n",
              " ['no', 'techo', 'mi', 'choza'],\n",
              " ['ni', 'techo', 'la', 'ajena', 'que', 'techo', 'la', 'choza'],\n",
              " ['de', 'maría', 'chucena']]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chucena_model = Word2Vec(tokenized_texts, vector_size=10, window=5, min_count=1, workers=4)\n",
        "\n",
        "#resulting vocabulary after min_count, and used by the trained model\n",
        "vocabulary = chucena_model.wv.index_to_key\n",
        "print(\"vocabulary\", vocabulary)\n",
        "\n",
        "# Create a list of tokenized texts based on the vocabulary\n",
        "tokenized_texts_with_min_count = [[token for token in sentence if token in vocabulary] for sentence in tokenized_texts]\n",
        "print(\"tokenized text with min_count applied\", tokenized_texts_with_min_count)\n",
        "\n",
        "# save the model\n",
        "chucena_model.save(\"chucena_model.w2v\")\n",
        "# inspect the model by looking for the most similar words for a test word\n",
        "print(chucena_model.wv.most_similar('choza', topn=5))\n",
        "print(chucena_model.wv[\"choza\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKsU-yb_JURt",
        "outputId": "3c499326-b762-4957-ff94-9ccebd31c836"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary ['techo', 'la', 'choza', 'ajena', 'chucena', 'maría', 'de', 'que', 'ni', 'mi', 'no', 'techas', 'o', 'tu', 'tú']\n",
            "tokenized text with min_count applied [['maría', 'chucena', 'tú', 'techas', 'tu', 'choza'], ['o', 'techas', 'la', 'ajena', 'no', 'techo', 'mi', 'choza'], ['ni', 'techo', 'la', 'ajena', 'que', 'techo', 'la', 'choza'], ['de', 'maría', 'chucena'], ['maría', 'chucena', 'tú', 'techas', 'tu', 'choza'], ['o', 'techas', 'la', 'ajena', 'no', 'techo', 'mi', 'choza'], ['ni', 'techo', 'la', 'ajena', 'que', 'techo', 'la', 'choza'], ['de', 'maría', 'chucena'], ['no', 'techo', 'mi', 'choza'], ['ni', 'techo', 'la', 'ajena', 'que', 'techo', 'la', 'choza'], ['de', 'maría', 'chucena'], ['no', 'techo', 'mi', 'choza'], ['ni', 'techo', 'la', 'ajena', 'que', 'techo', 'la', 'choza'], ['de', 'maría', 'chucena']]\n",
            "[('no', 0.4710186719894409), ('que', 0.4278322160243988), ('la', 0.330678790807724), ('techo', 0.3028535544872284), ('o', 0.3011913001537323)]\n",
            "[ 0.07312897  0.05068218  0.06778771  0.00768481  0.0635578  -0.03405765\n",
            " -0.00925233  0.05781493 -0.07542702 -0.03944864]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Going beyond words\n",
        "What happens if we have phrases instead of words?\n",
        "Using spaCy library, it is possible to obtain the vector representation for a text by averaging word vectors"
      ],
      "metadata": {
        "id": "zzTVR92beiTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "\n",
        "# Load the space model\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "# Process a sentence using the model\n",
        "doc = nlp(\"We do not know if AI developed self-awareness\")\n",
        "\n",
        "# average vector for entire sentence\n",
        "print(doc.vector)\n",
        "\n",
        "# vector for individual words\n",
        "print(doc[0].vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47JWjOt_MW14",
        "outputId": "001edf9a-6fc2-47c1-ac62-c1071d442abd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.46718082 -0.73682976  0.2654771   0.16771314 -0.35443217  0.02394564\n",
            "  0.06025836  0.46916622  0.05676441 -0.1679862  -0.5318343  -0.03253319\n",
            " -0.02277391  0.13460553 -0.4640514   0.03048846  0.80261564 -0.00327785\n",
            "  0.06049781 -0.3407663   0.51338863  0.23837724 -0.16018851 -0.52913445\n",
            "  0.27605042 -0.43683395  0.11041217  0.37744078 -0.20286807  0.25104433\n",
            " -0.0439132  -0.150646    0.10778917  0.0261063   0.20566204 -0.2547291\n",
            " -0.20749798 -0.7240614   0.13588211 -0.18661281 -0.18503119  0.39014086\n",
            "  0.39434797  0.14215569  0.18864498 -0.45987645 -0.32708937  0.00419698\n",
            "  0.11777029 -0.32849962 -0.24652882  0.21083622  0.15812314 -0.629973\n",
            "  0.4157961  -0.33089504  0.5009726   0.00976369  0.09171588 -0.37715572\n",
            "  0.45633593  0.60457075 -0.15391752 -0.08606204  0.40845996  0.12400439\n",
            "  0.24796727 -0.4031148   0.12707117  0.31356785 -0.13710594 -0.00254271\n",
            "  0.09609058 -0.3541966  -0.12192488  0.80667496  0.30960777 -0.7735901\n",
            " -0.0235024   0.23723836 -0.43696076 -0.23418555  0.05532515  0.0780948\n",
            "  0.14809522  0.21866474  0.54973114 -0.33137256 -0.11565765  0.555404\n",
            "  0.42880788 -0.2350559   0.3077262   0.22311512  0.19698346  0.24556056]\n",
            "[-0.9951539  -0.74701124 -0.17527255  0.70394266 -0.14261952 -0.67244\n",
            "  1.5296605   0.07309699 -0.26212674 -0.7497742   2.5011067   1.2575732\n",
            " -0.55882573  0.5296215  -1.3778366  -1.0669589   0.57450616  0.341292\n",
            " -0.625976   -0.77228224 -0.69118005  0.26802748  0.70521253 -0.90704507\n",
            " -0.7633872  -0.8250475  -0.15452868  0.567939   -0.77557755  0.84773815\n",
            " -0.12521225 -0.4862391  -0.196475    0.03290486 -0.4568924   1.103189\n",
            " -0.6515091  -0.72697186 -0.25300288  1.3117483  -1.3117894   0.17799708\n",
            "  0.08054452  0.72542924 -0.7874302  -0.7033996   0.4273935   3.076643\n",
            "  0.6285146  -0.03253078 -1.2305691  -1.0004473   1.8293328  -1.2260499\n",
            "  0.33081836 -0.8262043   0.5126325  -0.86804503 -0.06269687  0.9329036\n",
            "  0.8875978   0.542312    0.10856967 -0.346882    0.9978946   0.9223473\n",
            " -0.68188155 -0.69179964 -1.2515     -1.3269383  -0.61468154  0.05843402\n",
            "  0.9807763  -0.15987068 -0.90460014 -0.07180205  0.13093895  0.6616343\n",
            "  0.6556563   0.6933045  -1.1135666  -0.8337947  -0.15889585  0.5467209\n",
            "  0.86340475  0.40943748 -0.5085069   0.4044373   1.367644   -0.11841723\n",
            "  0.84216607  0.00535062  0.66097593 -0.42242905 -0.7668393   0.8571519 ]\n"
          ]
        }
      ]
    }
  ]
}